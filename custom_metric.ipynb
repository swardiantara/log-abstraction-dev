{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sward\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sward\\.cache\\huggingface\\hub\\models--hkunlp--instructor-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# FLP [88]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# LogSimilarity [52]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# LogCluster [95]\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m instructor_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mINSTRUCTOR\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhkunlp/instructor-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m SBERT \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/merged-manual-unique.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sward\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:287\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[0;32m    278\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[0;32m    281\u001b[0m     model_name_or_path,\n\u001b[0;32m    282\u001b[0m     token,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    286\u001b[0m ):\n\u001b[1;32m--> 287\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    300\u001b[0m         model_name_or_path,\n\u001b[0;32m    301\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# FLP [88]\n",
    "# LogSimilarity [52]\n",
    "# LogCluster [95]\n",
    "instructor_embedding = INSTRUCTOR('hkunlp/instructor-base')\n",
    "SBERT = SentenceTransformer('all-mpnet-base-v2')\n",
    "dataset = pd.read_csv('dataset/merged-manual-unique.csv')\n",
    "# Custom distance metric function\n",
    "log_dict = []\n",
    "for ind in dataset.index:\n",
    "    log_dict.append(['Represent the Drone Log message for clustering: ', dataset['message'][ind]])\n",
    "\n",
    "corpus = dataset['message'].to_list()\n",
    "def custom_distance_metric(log_messages, embedding_model='sbert', is_norm=True, metric='cosine'):\n",
    "    # Replace this with your own logic to calculate the distance\n",
    "    # This is just a placeholder example using TfidfVectorizer\n",
    "    if embedding_model == 'sbert':\n",
    "        corpus_embeddings = SBERT.encode(log_messages)\n",
    "        print(\"SBERT shape: \", corpus_embeddings[0].shape)\n",
    "    else:\n",
    "        corpus_embeddings = instructor_embedding.encode(log_messages)\n",
    "        print(\"instructor shape: \", corpus_embeddings[0].shape)\n",
    "    # Normalize the embeddings to unit length\n",
    "    if is_norm:\n",
    "        corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    return pairwise_distances(corpus_embeddings, corpus_embeddings, metric=metric)\n",
    "\n",
    "\n",
    "# Compute custom distance matrix\n",
    "dist_matrix = custom_distance_metric(log_dict, 'sbert', True, 'cosine') # Instructor\n",
    "# dist_matrix = custom_distance_metric(corpus, 'sbert', True, 'cosine') # Sentence Transformer\n",
    "\n",
    "# Clustering\n",
    "clustering_model = AgglomerativeClustering(n_clusters=None,  \n",
    "                                  affinity='precomputed',\n",
    "                                  linkage='average', \n",
    "                                  distance_threshold=0.05)\n",
    "clustering_model.fit(dist_matrix)\n",
    "\n",
    "# unlabeled dataset -> clustering -> initial_label -> human intervention / label correction -> labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustering_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cluster_assignment \u001b[38;5;241m=\u001b[39m \u001b[43mclustering_model\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m      2\u001b[0m pseudo_label \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m log_message \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clustering_model' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_assignment = clustering_model.labels_\n",
    "pseudo_label = []\n",
    "log_message = []\n",
    "clustered_sentences = {}\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_sentences:\n",
    "        clustered_sentences[cluster_id] = []\n",
    "\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "print(len(clustered_sentences))\n",
    "for i, cluster in clustered_sentences.items():\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    for element in cluster:\n",
    "        pseudo_label.append(i+1)\n",
    "        log_message.append(element)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350 342 267 407 295  27 411 415 239  27 408 431  49  49 456 334 260 385\n",
      "  21 377 351 245 266   6  52  52 388   6 289 371 303  28 399 343 418 392\n",
      " 298  18  18 369  15  28 173 173 288 264 248 307  17  17  17  17  17  17\n",
      "  15 319 285 270 451 275 417 309 365 296 306 455 439 429 256 313 325 459\n",
      " 269 355 465 352 281  44 420  44  47  47  47 416 242 453 207 290 236 409\n",
      " 305 410 243 443  50  50 251  12  12 446  12 315 357 393 457 396 403  46\n",
      " 367 227 444 383 293 413 358 276 246 379 387  56 339 402 235 344 422 286\n",
      " 406  14 322 441 327 368 353 345 433  38  38 405 467 370 304 241 378 184\n",
      " 423 437 463 280 434 257 194  31 366 240 328 247 249 294 397 438 234 274\n",
      " 183  76  76  91 346 279 324 347 321 238 466   7 122 301 278 172 432 287\n",
      " 202 282 359 394  40  40 430 440  25  65  23 462  84 326 414  65  65  23\n",
      "  62  84  65  62  33 216 221 219 268 160  33 114 114 316 337 412 464 215\n",
      " 468 310  21  56  21 398  34  34 204  19 428  19 400 120 254   0   0   0\n",
      "   0   0   0   5   0  13   5  13   5  13  13   5  13  13   0   0 425 151\n",
      " 449 255 335 140  68  68  68  68  68  68  68  68  68  68  68  68  68  68\n",
      "  68 284 308  46 395   4 333 198 424 119 127 419 283 380 442 244 391 178\n",
      " 384 259 320 314 445 159 208 401 389 389  22  22 194  31 381 189 103  41\n",
      "  41 144 141 341 311 152  25  57   4 452  57 386  77 253 317 188 362 361\n",
      " 237 107 374 197 220 404 182 153 271 348 201 435 166 340 233 106 273 109\n",
      "  30  42 364  42 447   2  42  30   1   1 356   1   1 354 118 272 390 142\n",
      " 291  86  86 100 436 214 323 331 448   3 461 211 116  96  93  93  96 338\n",
      "  29  29 363 372 318 158   2 263 454 329 143 129 373 200  56  21 177 230\n",
      " 192 427 170 426 330 262 206 191  16 225 450 218 134 134 162 139 360 226\n",
      " 299 312  59 212 154 302 179 231 161  59 186  88 297  69  36  36 223 171\n",
      " 250   8   8 117 421 332 217 176  93  93 196 121 458 168 300  80 336 265\n",
      "  11  11  11 382  10 232  10  79  95  70 205 131 292 277 222 126 164 148\n",
      " 108 124 190 375  75 150 224 115 145 155 133 175 112 110   1   1   1 147\n",
      " 199  87 156  60  67  67 132  43 460 149  85 229 180   3  58 165 163 123\n",
      " 167 185 193 210 169 105 181 213  94  89  54 203  89  99  99  32  32   2\n",
      " 209  73  98  53 135   7 376 146 261 157  26 130  78  71  74  20  20 228\n",
      " 258  15 104  37 137 113 187  51 136 252  72  81 349  77  35  82  83  39\n",
      " 101  14 128 111 138  16  92  90  37 195  61  63  97 106  55  24  24   9\n",
      "   9 102 125  48  45  64 174  66  66]\n"
     ]
    }
   ],
   "source": [
    "print(cluster_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ami_score_data: 0.804308555605715\n",
      "fm_score: 0.754514995423922\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "testing = pd.read_excel('dataset/merged-manual-unique.xlsx')\n",
    "testing['predicted_cluster'] = cluster_assignment\n",
    "testing = testing[testing['cluster'].notna()]\n",
    "\n",
    "ami_score_data = adjusted_mutual_info_score(testing['cluster'], testing['predicted_cluster'])\n",
    "print(f\"ami_score_data: {ami_score_data}\")\n",
    "\n",
    "# Assuming true_labels and predicted_labels are the ground truth and predicted cluster labels, respectively\n",
    "fm_score = fowlkes_mallows_score(testing['cluster'], testing['predicted_cluster'])\n",
    "print(f\"fm_score: {fm_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster</th>\n",
       "      <th>predicted_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A passenger aircraft is approaching. Descend a...</td>\n",
       "      <td>4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A passenger aircraft is nearby. Fly with caution</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abnormal compass function or GPS signal detect...</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerator is Over Range</td>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Account not logged in. Flight altitude and dis...</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Downlink Restored (after 0m 2.2s).</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Downlink Restored (after 0m 2.3s).</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Downlink Restored (after 0m 2.9s).</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Downlink Restored (after 0m 5.6s).</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Downlink Restored (after 0m 5.8s).</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message  label  cluster  \\\n",
       "0    A passenger aircraft is approaching. Descend a...      4     40.0   \n",
       "1     A passenger aircraft is nearby. Fly with caution      2     41.0   \n",
       "2    Abnormal compass function or GPS signal detect...      3     42.0   \n",
       "3                            Accelerator is Over Range      3     43.0   \n",
       "4    Account not logged in. Flight altitude and dis...      2     44.0   \n",
       "..                                                 ...    ...      ...   \n",
       "266                 Downlink Restored (after 0m 2.2s).      1     39.0   \n",
       "267                 Downlink Restored (after 0m 2.3s).      1     39.0   \n",
       "268                 Downlink Restored (after 0m 2.9s).      1     39.0   \n",
       "269                 Downlink Restored (after 0m 5.6s).      1     39.0   \n",
       "270                 Downlink Restored (after 0m 5.8s).      1     39.0   \n",
       "\n",
       "     predicted_cluster  \n",
       "0                  350  \n",
       "1                  342  \n",
       "2                  267  \n",
       "3                  407  \n",
       "4                  295  \n",
       "..                 ...  \n",
       "266                 68  \n",
       "267                 68  \n",
       "268                 68  \n",
       "269                 68  \n",
       "270                 68  \n",
       "\n",
       "[146 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_excel('evaluation/instructor-xl-norm-cosine-005.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
